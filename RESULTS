Author:

################
 FINAL METHOD
################
---------------------------------------------------------------------------
In Final stage of project the idea for clustering sentences is as follows :
---------------------------------------------------------------------------
The Idea is to cluster the sentences based on the local context vectors rather than the global context vectors. To Identify the clusters we are considering the words, which are selected based on number of occurences in the local context.This top  words act as dimensions(will be called dimension words in the rest of document) for generating the local context vectors for every instance of the file. As the generated vector matrix can be very sparse , Singular Value Decomposition is used to reduce the dimensionality of the context vector matrix . The resultant vector matrix from SVD is thus clustered using Hierarchical Clustering approach which inturn uses the Ward's minimum variance method to calculate the distance between the vectors.

System extracts the instances from the input file. System tokenizes all the instances , removes all the punctuations and stop words from the instances and then each sentence is represented as a list of words.Then the system goes through all the words and pick the top frequent words as the dimension for the context vectors. It removes target word from the dimension. Once the list with top words is generated, the system then generates int vectors with top words as dimensions. So for each sentence we have a context vector: a value of 1 represents that the corresponding dimension word is there in the sentence and 0 represents otherwise.

Example: dimension words=[hello, how, word, natural]:  contextvector=[0 0 1 1] : It means that the sentence has words word and natural in it.
 
Once the context vectors are generated for each sentence, singular value decomposition factorizes the sparse context vector matrix and generates a new matrix. Which then is clustered based on Ward's minimum variance method. We use the scipy toolkit for clustering. Scipy has methods for hierarchical clustering and we use the ward variance method and the distance metric is euclidean.

-----------------------------------------------------
For Generating the Defintion the idea is as follows :
-----------------------------------------------------
The Idea is to generate the definition based on the most common dimension words that occur in all context vectors and use context free grammar rules to generate the sentences. Once the system receives dimension words it identifies the nouns and verbs which are most frequent and generates sentences using Context Free Grammar Rules.


-------------------------------------------------
For Selecting the example the idea is as follows:
-------------------------------------------------
Once we have the all instances that are in a cluster, we look at number of dimension words present in them i.e the number of 1's in the context vector. We then pick the sentence that has the highest number of dimension words present in it or the highest number of 1's as the example for that cluster.

-------------------------
Performance of All Words:
-------------------------
ive-verb-shard014

        S1	      S2	      S0	   TOTAL	
  C0:       20	       8	      20	      48	(48.00)
  C1:        2	       6	       4	      12	(12.00)
  C2:        7	       5	      21	      33	(33.00)
  C3:*       1	       0	       6	       7	(7.00)
 TOTAL      30	      19	      51	     100
         (30.00)   (19.00)   (51.00)
Precision = 50.54(47/93)
Recall = 47.00(47/100+0)
F-Measure = 48.70

Legend of Sense Tags
S0 = live.1
S1 = live.2
S2 = live.3
_________________________________________________________________________________________
_________________________________________________________________________________________

manner-noun-shard014

S1	      S0	   TOTAL	
  C0:        8	       5	      13	(13.00)
  C1:       33	      39	      72	(72.00)
  C2:*       7	       8	      15	(15.00)
 TOTAL      48	      52	     100
         (48.00)   (52.00)
Precision = 55.29(47/85)
Recall = 47.00(47/100+0)
F-Measure = 50.81

Legend of Sense Tags
S0 = manner.1
S1 = manner.2
_________________________________________________________________________________________
_________________________________________________________________________________________

whale-night-shard014

S0	      S1	   TOTAL	
  C0:      140	       8	     148	(10.06)
  C1:      345	     662	    1007	(68.46)
  C2:*      75	     241	     316	(21.48)
 TOTAL     560	     911	    1471
         (38.07)   (61.93)
Precision = 69.44(802/1155)
Recall = 54.52(802/1471+0)
F-Measure = 61.08

Legend of Sense Tags
S0 = w_n.night
S1 = w_n.whale
_________________________________________________________________________________________
_________________________________________________________________________________________

God-noun-chime006

S2	      S0	      S1	   TOTAL	
  C0:        0	      14	       1	      15	(13.64)
  C2:        2	      37	       8	      47	(42.73)
  C3:        3	      22	       5	      30	(27.27)
  C1:*       0	      18	       0	      18	(16.36)
 TOTAL       5	      91	      14	     110
         (4.55)   (82.73)   (12.73)
Precision = 45.65(42/92)
Recall = 38.18(42/110+0)
F-Measure = 41.58

Legend of Sense Tags
S0 = God.Supreme_Power
S1 = God.a
S2 = God.idol_graven
_________________________________________________________________________________________
_________________________________________________________________________________________

tell-verb-chime006

S4	      S3	      S2	      S0#	      S1#	   TOTAL	
  C0:       32	      15	      28	       4	       1	      80	(79.21)
  C1:        0	       1	       3	       0	       0	       4	(3.96)
  C2:        4	       1	       9	       3	       0	      17	(16.83)
 TOTAL      36	      17	      40	       7	       1	     101
         (35.64)   (16.83)   (39.60)   (6.93)   (0.99)
Precision = 41.58(42/101)
Recall = 41.58(42/101+0)
F-Measure = 41.58

Legend of Sense Tags
S0 = tell.Assure
S1 = tell.confused
S2 = tell.let
S3 = tell.narrate_recite
S4 = tell.state_say
_________________________________________________________________________________________
_________________________________________________________________________________________

priest-heaven-chime006

S0	      S1	   TOTAL	
  C1:      214	     130	     344	(34.40)
  C3:        1	     218	     219	(21.90)
  C0:*     121	      56	     177	(17.70)
  C2:*     164	      96	     260	(26.00)
 TOTAL     500	     500	    1000
         (50.00)   (50.00)
Precision = 76.73(432/563)
Recall = 43.20(432/1000+0)
F-Measure = 55.28

Legend of Sense Tags
S0 = p_h.heaven
S1 = p_h.priest
_________________________________________________________________________________________
_________________________________________________________________________________________

believe-verb-kasir003

 S0	      S1	   TOTAL	
  C0:       15	      17	      32	(32.00)
  C2:       17	      32	      49	(49.00)
  C1:*       9	      10	      19	(19.00)
 TOTAL      41	      59	     100
         (41.00)   (59.00)
Precision = 58.02(47/81)
Recall = 47.00(47/100+0)
F-Measure = 51.93

Legend of Sense Tags
S0 = believed.1
S1 = believed.2
_________________________________________________________________________________________
_________________________________________________________________________________________

idea-noun-kasir003

S0	      S1	      S2	      S3#	   TOTAL	
  C0:       34	       7	       7	       7	      55	(55.00)
  C1:       14	       8	       1	       3	      26	(26.00)
  C2:       11	       3	       5	       0	      19	(19.00)
 TOTAL      59	      18	      13	      10	     100
         (59.00)   (18.00)   (13.00)   (10.00)
Precision = 47.00(47/100)
Recall = 47.00(47/100+0)
F-Measure = 47.00

Legend of Sense Tags
S0 = idea.1
S1 = idea.2
S2 = idea.3
S3 = idea.4
_________________________________________________________________________________________
_________________________________________________________________________________________

women-friend-kasir003

 S0	      S1	   TOTAL	
  C0:      697	     488	    1185	(82.06)
  C1:       16	     243	     259	(17.94)
 TOTAL     713	     731	    1444
         (49.38)   (50.62)
Precision = 65.10(940/1444)
Recall = 65.10(940/1444+0)
F-Measure = 65.10

Legend of Sense Tags
S0 = w_f.friend
S1 = w_f.women

_________________________________________________________________________________________
_________________________________________________________________________________________

lines-noun-6senses.xml

S2	      S0	      S1	      S4	      S3	      S5#	   TOTAL	
  C0:       23	       1	      38	     402	      40	      19	     523	(12.61)
  C1:      212	     339	     206	     621	     235	     272	    1885	(45.47)
  C2:       82	       6	     104	     356	      69	      88	     705	(17.00)
  C3:        9	       1	       4	     438	      38	       5	     495	(11.94)
  C4:       23	      26	      22	     400	      47	      20	     538	(12.98)
 TOTAL     349	     373	     374	    2217	     429	     404	    4146
         (8.42)   (9.00)   (9.02)   (53.47)   (10.35)   (9.74)
Precision = 22.94(951/4146)
Recall = 22.94(951/4146+0)
F-Measure = 22.94

Legend of Sense Tags
S0 = lines.cord
S1 = lines.division
S2 = lines.formation
S3 = lines.phone
S4 = lines.product
S5 = lines.text

_________________________________________________________________________________________
_________________________________________________________________________________________ 

pmss-noun-4senses.txt

S2	      S3	      S1	      S0	   TOTAL	
  C0:     1340	     559	     952	     953	    3804	(38.04)
  C1:      432	     747	     506	     530	    2215	(22.15)
  C2:      269	     523	     502	     446	    1740	(17.40)
  C3:      426	     138	     483	     496	    1543	(15.43)
  C4:*      33	     533	      57	      75	     698	(6.98)
 TOTAL    2500	    2500	    2500	    2500	   10000
         (25.00)   (25.00)   (25.00)   (25.00)
Precision = 33.16(3085/9302)
Recall = 30.85(3085/10000+0)
F-Measure = 31.97

Legend of Sense Tags
S0 = P_M_S_S.MURDERERS
S1 = P_M_S_S.PLAINTIFF
S2 = P_M_S_S.SKELETON
S3 = P_M_S_S.STRONGMAN

-------------------------------
BEST WORD BASED ON PERFORMANCE
-------------------------------

The best preforming word based on precision scores is the verb believe (58.02%) and the best result for name conflate are for the words priest and heaven (76.73).

-------------------------------
WORST WORD BASED ON PERFORMANCE
-------------------------------

The worst performing word based on precision scores is the noun lines (22.94%) and the worst result for name conflate are for the words women and friend (65.10%).
